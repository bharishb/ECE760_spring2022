{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53638ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "  \n",
    "# open file\n",
    "file = tarfile.open('./languageID.tgz')\n",
    "  \n",
    "# extracting file\n",
    "file.extractall('./train_data')\n",
    "  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6adde053",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = ['e', 'j', 's']\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fbafd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "train_data/languageID/e0.txt\n",
      "count = [ 67.   8.  28.  25. 142.  16.  12.  66.  61.   0.   9.  46.  25.  75.\n",
      "  88.  17.   0.  72.  76. 100.  38.  13.  28.   0.  16.   1. 236.]\n",
      "train_data/languageID/e1.txt\n",
      "count = [ 69.   5.  10.  23. 108.  16.   8.  48.  51.   3.   1.  22.  25.  43.\n",
      "  59.  12.   0.  57.  73.  87.  27.   6.  15.   0.  19.   1. 181.]\n",
      "train_data/languageID/e2.txt\n",
      "count = [ 40.   8.  15.  17.  92.  18.  15.  43.  44.   0.   5.  20.  13.  41.\n",
      "  55.  19.   0.  44.  54.  60.  14.   6.  10.   1.   8.   2. 139.]\n",
      "train_data/languageID/e3.txt\n",
      "count = [138.  30.  48.  50. 225.  41.  24. 101. 123.   3.   5.  62.  54. 134.\n",
      " 148.  32.   3. 122. 151. 189.  59.  24.  42.   1.  35.   0. 391.]\n",
      "train_data/languageID/e4.txt\n",
      "count = [ 41.   5.  16.  18. 102.  21.  24.  52.  51.   0.   2.  24.  20.  52.\n",
      "  72.  25.   0.  56.  51.  66.  24.  10.  10.   3.  13.   1. 145.]\n",
      "train_data/languageID/e5.txt\n",
      "count = [210.  32.  63.  54. 313.  55.  68. 136. 178.   6.  10. 107.  60. 188.\n",
      " 179.  46.   1. 156. 204. 256.  81.  31.  52.   4.  32.   1. 557.]\n",
      "train_data/languageID/e6.txt\n",
      "count = [ 43.   4.   6.  15.  74.  21.  11.  38.  32.   0.   4.  17.  16.  29.\n",
      "  48.  10.   0.  45.  50.  50.  16.   7.   9.   2.  12.   0. 125.]\n",
      "train_data/languageID/e7.txt\n",
      "count = [144.  32.  68.  69. 257.  60.  52. 121. 160.   3.  12.  74.  46. 148.\n",
      " 176.  45.   2. 128. 170. 202.  69.  19.  36.   3.  30.   0. 470.]\n",
      "train_data/languageID/e8.txt\n",
      "count = [ 42.  18.  18.  15. 101.  11.  15.  40.  30.   2.   2.  21.  13.  44.\n",
      "  47.  17.   0.  49.  45.  61.  19.  10.   5.   2.  17.   2. 142.]\n",
      "train_data/languageID/e9.txt\n",
      "count = [116.  26.  53.  46. 180.  27.  35.  69. 108.   4.   6.  45.  38. 122.\n",
      " 103.  30.   2.  85. 127. 141.  56.  14.  27.   1.  27.   1. 326.]\n",
      "train_data/languageID/e10.txt\n",
      "count = [164.  32.  53.  57. 311.  55.  51. 140. 140.   3.   6.  85.  64. 139.\n",
      " 182.  53.   3. 141. 186. 225.  65.  31.  47.   4.  38.   2. 498.]\n",
      "train_data/languageID/e11.txt\n",
      "count = [199.  47.  70.  86. 352.  78.  47. 143. 170.   1.  15. 124.  59. 191.\n",
      " 236.  38.   3. 147. 194. 272.  86.  35.  57.   2.  43.   2. 618.]\n",
      "train_data/languageID/e12.txt\n",
      "count = [122.  23.  59.  36. 196.  35.  15.  89. 103.   0.   8.  48.  38. 106.\n",
      " 111.  25.   1.  87. 124. 194.  58.  15.  24.   3.  25.   0. 348.]\n",
      "train_data/languageID/e13.txt\n",
      "count = [ 97.  24.  25.  32. 173.  38.  23.  85.  87.   0.   7.  45.  42.  90.\n",
      " 127.  22.   2.  79.  94. 179.  49.   8.  29.   2.  28.   1. 299.]\n",
      "train_data/languageID/e14.txt\n",
      "count = [113.  24.  33.  32. 164.  38.  33.  87.  87.   2.   5.  57.  45.  90.\n",
      " 104.  23.   1.  72. 109. 140.  36.   9.  23.   1.  19.   1. 322.]\n",
      "train_data/languageID/e15.txt\n",
      "count = [108.  19.  34.  42. 157.  31.  29.  67. 101.   0.   8.  42.  49.  91.\n",
      " 100.  27.   2.  84.  96. 149.  38.  16.  29.   0.  23.   1. 271.]\n",
      "train_data/languageID/e16.txt\n",
      "count = [159.  36.  66.  60. 316.  45.  35. 138. 138.   0.  14.  97.  53. 164.\n",
      " 168.  53.   0. 146. 169. 219.  56.  27.  46.   7.  32.   0. 477.]\n",
      "train_data/languageID/e17.txt\n",
      "count = [155.  26.  62.  53. 267.  58.  41. 110. 128.   3.  14.  65.  63. 149.\n",
      " 174.  45.   3. 107. 145. 200.  55.  22.  30.   2.  30.   1. 416.]\n",
      "train_data/languageID/e18.txt\n",
      "count = [126.  16.  31.  37. 166.  32.  21.  57.  98.   0.   7.  57.  43. 100.\n",
      "  90.  29.   0.  84. 105. 118.  46.  15.  24.   3.  23.   1. 302.]\n",
      "train_data/languageID/e19.txt\n",
      "count = [31.  8. 14. 17. 59. 12.  8. 20. 49.  0.  1. 10. 19. 39. 39. 13.  1. 30.\n",
      " 37. 44. 17.  7.  5.  1.  4.  0. 97.]\n",
      "j\n",
      "train_data/languageID/j0.txt\n",
      "count = [188.  15.  10.  27.  88.   6.  28.  40. 137.   5.  85.   1.  59.  69.\n",
      " 111.   4.   0.  59.  55.  68.  89.   0.  24.   0.  16.  11. 173.]\n",
      "train_data/languageID/j1.txt\n",
      "count = [192.  13.  13.  20.  95.   5.  19.  52. 147.   5.  71.   0.  73.  86.\n",
      " 133.   2.   0.  83.  61.  88. 118.   0.  28.   0.  25.  11. 186.]\n",
      "train_data/languageID/j2.txt\n",
      "count = [231.  17.   7.  37. 100.   6.  23.  61. 188.   2. 114.   0.  65. 102.\n",
      " 165.   0.   0.  75.  79.  84. 135.   0.  36.   0.  34.  18. 225.]\n",
      "train_data/languageID/j3.txt\n",
      "count = [132.  13.   6.  13.  52.   3.  17.  36. 115.   3.  60.   9.  37.  53.\n",
      " 100.   0.   0.  44.  47.  62.  74.   0.  22.   0.  14.   5. 136.]\n",
      "train_data/languageID/j4.txt\n",
      "count = [175.  14.   9.  22.  75.   6.  19.  53. 120.   6.  71.   4.  48.  75.\n",
      " 139.   0.   0.  47.  63.  82.  97.   0.  29.   0.  17.  13. 166.]\n",
      "train_data/languageID/j5.txt\n",
      "count = [223.  20.  10.  27.  88.   6.  22.  49. 157.   4.  92.   2.  55.  99.\n",
      " 125.   2.   0.  51.  62.  86.  92.   0.  36.   0.  16.  11. 181.]\n",
      "train_data/languageID/j6.txt\n",
      "count = [161.  11.   7.  27. 104.   7.  13.  41. 122.   1.  73.   0.  56.  72.\n",
      " 106.   0.   0.  57.  65.  86. 108.   0.  23.   0.  16.  11. 168.]\n",
      "train_data/languageID/j7.txt\n",
      "count = [191.  20.   6.  18. 102.   5.  21.  49. 154.   3.  88.   2.  60.  94.\n",
      " 147.   2.   0.  56.  71. 106. 106.   2.  27.   0.  24.  15. 188.]\n",
      "train_data/languageID/j8.txt\n",
      "count = [211.  23.   7.  22.  83.   8.  20.  44. 140.   4.  88.   2.  68.  88.\n",
      " 154.   0.   1.  81.  57.  92. 105.   1.  24.   0.  20.  11. 192.]\n",
      "train_data/languageID/j9.txt\n",
      "count = [181.   9.   3.  33.  74.   3.  18.  29. 108.   0.  79.   0.  48.  73.\n",
      " 124.   2.   0.  59.  43.  61.  86.   0.  33.   0.  20.   4. 151.]\n",
      "train_data/languageID/j10.txt\n",
      "count = [186.   9.   8.  19. 100.   5.  24.  54. 155.   4.  81.   2.  68.  70.\n",
      " 131.   0.   0.  68.  66. 103. 106.   1.  34.   0.  19.   7. 181.]\n",
      "train_data/languageID/j11.txt\n",
      "count = [197.  18.   6.  16.  82.   2.  24.  37. 155.   3.  88.   0.  70.  87.\n",
      " 143.   0.   0.  63.  62. 100. 104.   0.  39.   0.  14.  12. 182.]\n",
      "train_data/languageID/j12.txt\n",
      "count = [152.  18.   7.  20.  75.   6.  14.  39. 113.   3.  74.   0.  42.  73.\n",
      " 105.   0.   0.  45.  68.  70. 111.   0.  25.   0.  22.  10. 149.]\n",
      "train_data/languageID/j13.txt\n",
      "count = [220.  16.   7.  22.  89.   4.  22.  41. 179.   3.  93.   0.  58.  81.\n",
      " 129.   3.   0.  71.  67.  97. 102.   1.  39.   0.  27.  12. 198.]\n",
      "train_data/languageID/j14.txt\n",
      "count = [221.  15.  12.  25.  95.   4.  32.  48. 151.   2. 107.   0.  72.  89.\n",
      " 136.   0.   0.  73.  56.  80. 121.   0.  22.   0.  24.  16. 191.]\n",
      "train_data/languageID/j15.txt\n",
      "count = [166.   7.   6.  26.  82.   4.  19.  46. 129.   4.  66.   9.  50.  70.\n",
      " 122.   0.   0.  52.  53.  81.  76.   0.  27.   0.  15.   7. 165.]\n",
      "train_data/languageID/j16.txt\n",
      "count = [201.  13.   4.  23.  80.   4.  30.  43. 136.   0.  86.   1.  53.  90.\n",
      " 149.   4.   0.  59.  58.  83.  93.   0.  29.   0.  24.  12. 180.]\n",
      "train_data/languageID/j17.txt\n",
      "count = [206.   9.  10.  35.  92.   7.  24.  56. 168.   4.  84.   0.  58. 105.\n",
      " 157.   1.   0.  63.  62. 100.  93.   0.  33.   0.  20.  10. 193.]\n",
      "train_data/languageID/j18.txt\n",
      "count = [194.  12.   7.  22.  89.   5.  17.  44. 132.   2.  90.   0.  62.  74.\n",
      " 108.   0.   0.  60.  71.  75. 112.   0.  31.   0.  11.  14. 164.]\n",
      "train_data/languageID/j19.txt\n",
      "count = [185.  14.   5.  18.  86.   4.  23.  46. 150.   2.  60.   2.  76.  93.\n",
      " 124.   0.   0.  63.  63.  69. 100.   0.  24.   0.  21.  13. 170.]\n",
      "s\n",
      "train_data/languageID/s0.txt\n",
      "count = [177.   8.  75.  73. 239.  21.  12.  12.  98.  11.   1.  91.  44. 115.\n",
      " 149.  57.  20. 111. 128.  67.  66.  11.   1.   3.   7.  10. 322.]\n",
      "train_data/languageID/s1.txt\n",
      "count = [133.  11.  60.  71. 167.  14.   6.   4.  72.   7.   0.  69.  44.  79.\n",
      " 102.  32.   7.  89.  99.  47.  47.   9.   0.   3.  14.   1. 234.]\n",
      "train_data/languageID/s2.txt\n",
      "count = [228.  23.  79.  59. 219.  16.  20.   7. 118.  12.   0. 106.  49. 118.\n",
      " 129.  39.  17. 111. 121.  77.  68.   9.   0.   6.  16.   2. 328.]\n",
      "train_data/languageID/s3.txt\n",
      "count = [181.  16.  59.  80. 202.  14.  12.   4.  81.  21.   1. 104.  43.  80.\n",
      " 126.  51.  13. 105. 108.  58.  49.   9.   0.   8.  18.   7. 299.]\n",
      "train_data/languageID/s4.txt\n",
      "count = [234.  20.  77.  77. 214.  16.  14.   5.  99.   7.   0. 112.  51. 111.\n",
      " 146.  41.  15. 127. 124.  71.  71.  17.   0.   3.  13.   7. 343.]\n",
      "train_data/languageID/s5.txt\n",
      "count = [133.  15.  35.  44. 145.  11.   9.  11.  59.  13.   0.  70.  37.  64.\n",
      "  86.  30.  10.  83.  89.  48.  46.   3.   0.   2.   7.   4. 214.]\n",
      "train_data/languageID/s6.txt\n",
      "count = [ 93.   6.  35.  41. 109.   5.   6.   4.  43.   4.   0.  40.  18.  52.\n",
      "  83.  21.   9.  70.  69.  41.  34.   7.   0.   2.   8.   1. 159.]\n",
      "train_data/languageID/s7.txt\n",
      "count = [139.   8.  48.  59. 151.  14.   5.   6.  60.   6.   0.  68.  41.  75.\n",
      "  99.  23.   7.  69.  89.  52.  34.   6.   0.   5.   8.   2. 211.]\n",
      "train_data/languageID/s8.txt\n",
      "count = [242.  19.  92.  89. 249.  18.  19.  17. 108.  14.   1. 124.  58. 117.\n",
      " 166.  62.  13. 123. 149.  78.  80.  13.   0.   3.  19.   4. 386.]\n",
      "train_data/languageID/s9.txt\n",
      "count = [135.   7.  48.  51. 150.  10.  13.   3.  70.  12.   1.  74.  33.  67.\n",
      "  89.  37.  13.  73.  90.  38.  51.  11.   0.   5.  17.   5. 232.]\n",
      "train_data/languageID/s10.txt\n",
      "count = [184.  22.  55.  75. 195.   7.   8.   7.  81.  14.   1.  96.  43.  87.\n",
      " 128.  49.  15. 113. 107.  64.  50.  13.   0.   4.   4.   5. 279.]\n",
      "train_data/languageID/s11.txt\n",
      "count = [71.  6. 19. 27. 72.  2.  4.  2. 29.  5.  0. 41. 17. 27. 29. 20.  6. 34.\n",
      " 53. 17. 24.  2.  0.  1.  4.  2. 99.]\n",
      "train_data/languageID/s12.txt\n",
      "count = [202.  30.  59.  86. 222.  10.  18.  13.  93.  13.   0.  85.  43. 112.\n",
      " 153.  42.  15. 120. 141.  78.  88.   5.   0.   4.  12.   7. 341.]\n",
      "train_data/languageID/s13.txt\n",
      "count = [122.   5.  39.  39. 107.   9.   6.   7.  45.   7.   0.  58.  22.  61.\n",
      "  58.  17.   5.  48.  67.  31.  33.   8.   0.   4.   6.   3. 162.]\n",
      "train_data/languageID/s14.txt\n",
      "count = [186.  23.  55.  77. 202.  10.  12.   6.  85.  12.   0.  84.  44. 102.\n",
      " 116.  50.  14. 111.  97.  72.  64.  13.   4.   3.  12.   9. 300.]\n",
      "train_data/languageID/s15.txt\n",
      "count = [142.  12.  62.  59. 179.  10.  16.   7.  80.   9.   0.  83.  36.  88.\n",
      " 121.  38.  10.  84.  94.  45.  60.  18.   0.   4.   7.   3. 265.]\n",
      "train_data/languageID/s16.txt\n",
      "count = [195.  15.  62.  66. 180.  15.   9.   7.  92.   5.   1.  85.  38.  99.\n",
      "  99.  48.  13.  79. 114.  61.  52.   4.   0.   7.  15.  13. 275.]\n",
      "train_data/languageID/s17.txt\n",
      "count = [181.  26.  75.  76. 206.  13.  12.  11.  99.  15.   0.  94.  45.  87.\n",
      " 127.  33.  19. 100. 141.  57.  74.   7.   0.   2.   9.   8. 296.]\n",
      "train_data/languageID/s18.txt\n",
      "count = [218.  15.  75.  71. 183.  11.  13.   7.  98.  10.   1. 115.  40.  93.\n",
      " 135.  36.  13. 108. 134.  66.  66.  16.   3.   6.  27.   6. 338.]\n",
      "train_data/languageID/s19.txt\n",
      "count = [139.  13.  41.  47. 126.   4.  11.   9.  55.  13.   0.  64.  27.  67.\n",
      "  74.  30.   8.  74.  63.  38.  38.   4.   0.   5.   8.   4. 190.]\n"
     ]
    }
   ],
   "source": [
    "char_count = np.zeros([3,20,27])\n",
    "for k, label in enumerate(y_label):\n",
    "    print(label);\n",
    "    #print(k);\n",
    "    #char_count = np.zeros([3,10,27])\n",
    "    for i in range(20):\n",
    "        print('train_data/languageID/%s'%label+'%d'%i+'.txt')\n",
    "        f = open('train_data/languageID/%s' % label+ '%d' % i+'.txt')\n",
    "        data = f.read();\n",
    "        for j in data:\n",
    "            if((j!='\\n')):\n",
    "                if((j == ' ')):\n",
    "                    char_count[k][i][26] += 1;\n",
    "                else:\n",
    "                    char_count[k][i][ord(j)-97] += 1;\n",
    "        #print(\"space_count =\",char_count[26]);\n",
    "        print(\"count =\", char_count[k][i])\n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3fceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char count sum : [ 910.  168.  325.  332. 1594.  286.  264.  714.  838.   21.   56.  438.\n",
      "  310.  876.  975.  253.    8.  814. 1001. 1212.  403.  140.  234.   17.\n",
      "  209.    9. 2712.]\n",
      "char count sum : [1.885e+03 1.550e+02 7.800e+01 2.460e+02 8.610e+02 5.500e+01 2.000e+02\n",
      " 4.540e+02 1.388e+03 3.300e+01 8.210e+02 2.000e+01 5.690e+02 8.110e+02\n",
      " 1.304e+03 1.200e+01 1.000e+00 6.120e+02 6.030e+02 8.150e+02 1.010e+03\n",
      " 3.000e+00 2.820e+02 0.000e+00 2.020e+02 1.100e+02 1.766e+03]\n",
      "char count sum : [1.695e+03 1.330e+02 6.080e+02 6.440e+02 1.845e+03 1.390e+02 1.160e+02\n",
      " 7.300e+01 8.080e+02 1.070e+02 4.000e+00 8.580e+02 4.180e+02 8.780e+02\n",
      " 1.175e+03 3.930e+02 1.240e+02 9.610e+02 1.066e+03 5.770e+02 5.460e+02\n",
      " 9.500e+01 1.000e+00 4.000e+01 1.270e+02 4.300e+01 2.728e+03]\n"
     ]
    }
   ],
   "source": [
    "likelihood = np.zeros([3,27]);\n",
    "alpha = 0.5;\n",
    "for i in range(3):\n",
    "    print(\"char count sum :\", np.sum(char_count[i][:10],axis=0))\n",
    "    likelihood[i]= (np.sum(char_count[i][:10],axis=0) + alpha)/(np.sum(np.sum(char_count[i][:10],axis=0)) + 27*alpha) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3534cea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.01685115e-02, 1.11349744e-02, 2.15099950e-02, 2.19725756e-02,\n",
       "        1.05369238e-01, 1.89327606e-02, 1.74789361e-02, 4.72162564e-02,\n",
       "        5.54105402e-02, 1.42078308e-03, 3.73368578e-03, 2.89773666e-02,\n",
       "        2.05187510e-02, 5.79216917e-02, 6.44639022e-02, 1.67520238e-02,\n",
       "        5.61704940e-04, 5.38245498e-02, 6.61820585e-02, 8.01255576e-02,\n",
       "        2.66644639e-02, 9.28465224e-03, 1.54964480e-02, 1.15645135e-03,\n",
       "        1.38443747e-02, 6.27787874e-04, 1.79249959e-01],\n",
       "       [1.31765610e-01, 1.08669066e-02, 5.48586603e-03, 1.72263182e-02,\n",
       "        6.02047591e-02, 3.87854223e-03, 1.40116706e-02, 3.17621161e-02,\n",
       "        9.70334393e-02, 2.34110207e-03, 5.74094133e-02, 1.43261470e-03,\n",
       "        3.97987351e-02, 5.67105769e-02, 9.11632132e-02, 8.73545547e-04,\n",
       "        1.04825466e-04, 4.28037318e-02, 4.21747790e-02, 5.69901115e-02,\n",
       "        7.06174220e-02, 2.44592753e-04, 1.97421294e-02, 3.49418219e-05,\n",
       "        1.41514379e-02, 7.72214263e-03, 1.23449457e-01],\n",
       "       [1.04560451e-01, 8.23286362e-03, 3.75258241e-02, 3.97459221e-02,\n",
       "        1.13810860e-01, 8.60287996e-03, 7.18448398e-03, 4.53270019e-03,\n",
       "        4.98597021e-02, 6.62945947e-03, 2.77512257e-04, 5.29431717e-02,\n",
       "        2.58086399e-02, 5.41765595e-02, 7.24923684e-02, 2.42669051e-02,\n",
       "        7.67783910e-03, 5.92951189e-02, 6.57704049e-02, 3.56140730e-02,\n",
       "        3.37023219e-02, 5.88942678e-03, 9.25040856e-05, 2.49761031e-03,\n",
       "        7.86284728e-03, 2.68261848e-03, 1.68264932e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f49bc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7841.86544706 -8771.43307908 -8467.28204401]\n",
      "[-7842.96405935 -8772.53169136 -8468.3806563 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(x):\n",
    "    prob = np.zeros(3);\n",
    "    for i in range(3):\n",
    "        for j in range(27):\n",
    "            prob[i] = prob[i] + x[j]*np.log(likelihood[i][j])\n",
    "    prob_label = np.log(1/3);\n",
    "    print(prob)\n",
    "    print(prob+prob_label); \n",
    "    return np.argmax(prob+prob_label);\n",
    "    \n",
    "predict(char_count[0][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b971b461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7841.86544706 -8771.43307908 -8467.28204401]\n",
      "[-7842.96405935 -8772.53169136 -8468.3806563 ]\n",
      "[ -9346.21187506 -10407.28383319 -10056.2521139 ]\n",
      "[ -9347.31048735 -10408.38244548 -10057.35072619]\n",
      "[-5285.490455   -5836.36279816 -5681.09371085]\n",
      "[-5286.58906729 -5837.46141045 -5682.19232314]\n",
      "[-4742.75350354 -5182.13334878 -5178.66342058]\n",
      "[-4743.85211583 -5183.23196107 -5179.76203287]\n",
      "[-4683.03931476 -5181.4771028  -5047.72526661]\n",
      "[-4684.13792705 -5182.57571509 -5048.8238789 ]\n",
      "[-4600.23893454 -5033.95182275 -4960.51318253]\n",
      "[-4601.33754683 -5035.05043504 -4961.61179482]\n",
      "[-7678.84975509 -8631.73226903 -8289.27692001]\n",
      "[-7679.94836738 -8632.83088132 -8290.3755323 ]\n",
      "[-6879.7553713  -7609.76619908 -7355.87446364]\n",
      "[-6880.85398359 -7610.86481137 -7356.97307593]\n",
      "[-4598.25099325 -5078.38958947 -4864.17346173]\n",
      "[-4599.34960553 -5079.48820176 -4865.27207402]\n",
      "[-1655.85674191 -1817.25793193 -1735.59839096]\n",
      "[-1656.95535419 -1818.35654422 -1736.69700325]\n",
      "[-4543.2495348  -4132.78009678 -5003.94991962]\n",
      "[-4544.34814709 -4133.87870907 -5005.04853191]\n",
      "[-4598.84884832 -4106.23862738 -5052.08987498]\n",
      "[-4599.94746061 -4107.33723966 -5053.18848727]\n",
      "[-3822.35049377 -3439.04118104 -4175.60861132]\n",
      "[-3823.44910606 -3440.13979333 -4176.70722361]\n",
      "[-4826.54078394 -4335.66678892 -5295.51553674]\n",
      "[-4827.63939623 -4336.76540121 -5296.61414903]\n",
      "[-4936.70057783 -4377.56104503 -5343.72017252]\n",
      "[-4937.79919012 -4378.65965732 -5344.81878481]\n",
      "[-3854.25611203 -3538.47951018 -4210.0851062 ]\n",
      "[-3855.35472431 -3539.57812247 -4211.18371849]\n",
      "[-4438.05042146 -3992.2468402  -4847.86318933]\n",
      "[-4439.14903375 -3993.34545249 -4848.96180162]\n",
      "[-4805.79302589 -4367.79181025 -5255.77479945]\n",
      "[-4806.89163818 -4368.89042254 -5256.87341174]\n",
      "[-4304.0699495  -3828.79727214 -4705.92906294]\n",
      "[-4305.16856179 -3829.89588443 -4707.02767523]\n",
      "[-4273.30919494 -3876.73269463 -4581.83687929]\n",
      "[-4274.40780723 -3877.83130691 -4582.93549158]\n",
      "[-4969.07803843 -5575.93970935 -4713.65177305]\n",
      "[-4970.17665072 -5577.03832164 -4714.75038534]\n",
      "[-1797.19448608 -2028.9871409  -1690.47514396]\n",
      "[-1798.29309837 -2030.08575319 -1691.57375625]\n",
      "[-5743.16634033 -6276.85404526 -5506.75397232]\n",
      "[-5744.26495262 -6277.95265755 -5507.85258461]\n",
      "[-2803.64201761 -3135.54462607 -2668.38577698]\n",
      "[-2804.7406299  -3136.64323836 -2669.48438927]\n",
      "[-5135.98888451 -5698.72685794 -4918.81374915]\n",
      "[-5137.0874968  -5699.82547023 -4919.91236144]\n",
      "[-4432.5303589  -4997.41066929 -4237.04229393]\n",
      "[-4433.62897118 -4998.50928158 -4238.14090621]\n",
      "[-4809.79425286 -5340.65875454 -4576.95547588]\n",
      "[-4810.89286515 -5341.75736683 -4578.05408817]\n",
      "[-5306.48515477 -5862.58243678 -5041.63848194]\n",
      "[-5307.58376706 -5863.68104907 -5042.73709423]\n",
      "[-5519.5366513  -6166.48935007 -5278.79965195]\n",
      "[-5520.63526359 -6167.58796235 -5279.89826424]\n",
      "[-3373.41911356 -3744.13497713 -3202.78604695]\n",
      "[-3374.51772585 -3745.23358942 -3203.88465924]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "pred = np.zeros([3, 10])\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        pred[i][j] = predict(char_count[i][j+10]);\n",
    "\n",
    "print(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46a6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
